_base_: "eval.yml"

model:
  type: ImageTextCoDecomposition
  clip_model: ViT-B/16  # NOTE only ViT-based backbones are supported.
  ie_freeze: 6  # index [1 ~ 12] 
  ie_ignore_last_attn: true 
  masker:
    type: Masker
    decoder:
      type: GDecoder
      double: false
      n_layers: 0
      kernel_size: 3
      act: gelu
      norm: ln
    sim2mask:
      init_w: 10.0
      init_b: -2.5
      gumbel_tau: 1.0
      learnable: false

  w_kg: 8.0

  use_region_highlighting_prompt: true

  # tcl's loss
  w_tcl: 0.1
  pos_area: 0.25
  w_pos_area: 0.5
  w_neg_area: 0.05

  # total variation loss (paper's page 5)
  w_tv: 1.0

  w_hcl: 0.1
  w_tseg: 1.0
  use_word_highlighting_prompt: true

data:
  batch_size: 2
  pin_memory: false
  num_workers: 12
  seed: ${train.seed}
  dataset:
    meta:
      COCOCaption:
        type: img_txt_pair
        path: ./data/CC3M/
        prefix: "cc3m-train-{0000..0059}.tar"
        length: 300000
    train:
      - COCOCaption

  img_aug:
    deit_aug: false
    img_size: 224
    img_scale: [0.9, 1.0]

    # interpolation: bilinear
    # color_jitter: 0.4
    # auto_augment: 'rand-m9-mstd0.5-inc1'
    # re_prob: 0.25
    # re_mode: 'pixel'
    # re_count: 1
  text_aug: null
  num_words: 1
  word_type: noun

train:
  start_step: 0
  total_steps: 30000
  warmup_steps: 0
  ust_steps: 0
  base_lr: 6.4e-4
  # base_lr: 4e-4 
  weight_decay: 0.05
  # min_lr: 4e-5
  min_lr: 4e-5
  clip_grad: 5.0
  fp16: true
  fp16_comm: true # use fp16 grad compression for multi-node training
  seed: 10

  lr_scheduler:
    name: cosine

  optimizer:
    name: adamw
    eps: 1e-6
    betas: [0.9, 0.999]


evaluate:
  eval_only: false
  eval_freq: 10000

checkpoint:
  resume: ''
  save_topk: 1
  save_all: true  # if true, save every evaluation step

output: ???
tag: default
print_freq: 20
seed: 0
method_name: ???
wandb: false
